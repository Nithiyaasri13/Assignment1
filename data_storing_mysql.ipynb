{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pymysql.connections.Connection object at 0x000002280930A390>\n",
      "The database has been created\n",
      "information_schema\n",
      "mysql\n",
      "performance_schema\n",
      "record\n",
      "sakila\n",
      "sportradar\n",
      "stduent\n",
      "sys\n",
      "world\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "\n",
    "# Establish connection\n",
    "mydb = pymysql.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"nITHIY@1234\"\n",
    ")\n",
    "\n",
    "print(mydb)\n",
    "\n",
    "# Create cursor\n",
    "Mycursor = mydb.cursor()  # Cursor is the interaction point between MySQL and Python\n",
    "\n",
    "# Create database\n",
    "Mycursor.execute('CREATE DATABASE SportRadar')\n",
    "print('The database has been created')\n",
    "\n",
    "# Show databases\n",
    "Mycursor.execute('SHOW DATABASES')\n",
    "for i in Mycursor:\n",
    "    print(''.join(i))\n",
    "\n",
    "# Close the connection\n",
    "mydb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['category_id', 'category_name'], dtype='object')\n",
      "Table has been created (or already exists).\n",
      "The data has been uploaded. Total rows in table: 18\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "\n",
    "# Establishing a connection to the database\n",
    "mydb = pymysql.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"nITHIY@1234\",\n",
    "    database=\"SportRadar\"  # Ensure you're connecting to the correct database\n",
    ")\n",
    "\n",
    "# Creating a cursor object\n",
    "Mycursor = mydb.cursor()\n",
    "\n",
    "# Import CSV file into a DataFrame\n",
    "df = pd.read_csv(r'C:\\Users\\Nithiyaasri G\\python projects\\Mini_Project\\venv\\Scripts\\table_2.csv')\n",
    "Categories_table = df.copy()\n",
    "\n",
    "# Data preprocessing\n",
    "print(Categories_table.columns)  # Check the column names to ensure they are correct\n",
    "\n",
    "# Drop duplicates based on 'category_id'\n",
    "Categories_table.drop_duplicates(subset=['category_id'], inplace=True)\n",
    "\n",
    "# Create table (use IF NOT EXISTS to avoid errors if the table already exists)\n",
    "create_table_query = '''\n",
    "CREATE TABLE IF NOT EXISTS SportRadar.Categories_table (\n",
    "    category_id VARCHAR(50),\n",
    "    category_name VARCHAR(100) NOT NULL,\n",
    "    PRIMARY KEY (category_id)\n",
    ");\n",
    "'''\n",
    "Mycursor.execute(create_table_query)\n",
    "print('Table has been created (or already exists).')\n",
    "\n",
    "# Check if the DataFrame has the correct columns\n",
    "if 'category_id' not in Categories_table.columns or 'category_name' not in Categories_table.columns:\n",
    "    print(\"Error: DataFrame does not have 'category_id' or 'category_name' columns.\")\n",
    "else:\n",
    "    # Values to store\n",
    "    insert_into = 'INSERT IGNORE INTO SportRadar.Categories_table (category_id, category_name) VALUES (%s, %s)'\n",
    "\n",
    "    # Insert the rows through the loop\n",
    "    for index, row in Categories_table.iterrows():\n",
    "        try:\n",
    "            # Ensure column names are correct\n",
    "            Mycursor.execute(insert_into, (row['category_id'], row['category_name']))\n",
    "        except Exception as e:\n",
    "            print(f\"Error inserting row {index}: {row.to_dict()}\\nError: {e}\")\n",
    "\n",
    "    # Commit the transaction after all rows are inserted\n",
    "    mydb.commit()\n",
    "\n",
    "    # Ensure the data has been stored\n",
    "    Mycursor.execute('SELECT COUNT(*) FROM SportRadar.Categories_table')\n",
    "    row_count = Mycursor.fetchone()[0]\n",
    "    print(f'The data has been uploaded. Total rows in table: {row_count}')\n",
    "\n",
    "# Close the cursor and connection\n",
    "Mycursor.close()\n",
    "mydb.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the dataset: Index(['id', 'name', 'type', 'gender', 'category_id', 'parent_id'], dtype='object')\n",
      "                    id                               name     type gender  \\\n",
      "0   sr:competition:620                         Hopman Cup    mixed  mixed   \n",
      "1   sr:competition:660                     World Team Cup    mixed    men   \n",
      "2   sr:competition:990         ATP Challenger Tour Finals  singles    men   \n",
      "3  sr:competition:1207  Championship International Series  singles  women   \n",
      "4  sr:competition:2100                          Davis Cup    mixed    men   \n",
      "\n",
      "       category_id            parent_id competition_id  \n",
      "0  sr:category:181                  NOT         comp_0  \n",
      "1    sr:category:3                  NOT         comp_1  \n",
      "2   sr:category:72  sr:competition:6239         comp_2  \n",
      "3    sr:category:6                  NOT         comp_3  \n",
      "4   sr:category:76                  NOT         comp_4  \n",
      "The data has been uploaded. Total rows in table: 5842\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "\n",
    "# Establishing a connection to the database\n",
    "mydb = pymysql.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"nITHIY@1234\",\n",
    "    database=\"SportRadar\"  # Ensure you're connecting to the correct database\n",
    ")\n",
    "\n",
    "# Creating a cursor object\n",
    "Mycursor = mydb.cursor()\n",
    "\n",
    "# Import file to store\n",
    "df = pd.read_csv(r'C:\\Users\\Nithiyaasri G\\python projects\\Mini_Project\\venv\\Scripts\\table_1.csv')\n",
    "Competitions_table = df.copy()\n",
    "\n",
    "# Data Preprocessing\n",
    "\n",
    "# Check column names to make sure 'competition_id' exists\n",
    "print(\"Columns in the dataset:\", Competitions_table.columns)\n",
    "\n",
    "# If 'competition_id' is missing, generate it as before\n",
    "if 'competition_id' not in Competitions_table.columns:\n",
    "    Competitions_table['competition_id'] = 'comp_' + Competitions_table.index.astype(str)\n",
    "\n",
    "# Drop duplicates by 'competition_id'\n",
    "Competitions_table.drop_duplicates(subset=['competition_id'], inplace=True)\n",
    "\n",
    "# Convert missing values in 'parent_id' to None (for MySQL compatibility)\n",
    "Competitions_table['parent_id'] = Competitions_table['parent_id'].apply(lambda x: None if pd.isna(x) else x)\n",
    "\n",
    "# Check the cleaned DataFrame\n",
    "print(Competitions_table.head())\n",
    "\n",
    "# Create table in MySQL (if not exists)\n",
    "Mycursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS SportRadar.Competitions_table (\n",
    "        competition_id VARCHAR(50), \n",
    "        competition_name VARCHAR(100) NOT NULL,\n",
    "        parent_id VARCHAR(50) NULL,\n",
    "        type VARCHAR(20) NOT NULL,\n",
    "        gender VARCHAR(10) NOT NULL,\n",
    "        category_id VARCHAR(50),\n",
    "        PRIMARY KEY(competition_id),\n",
    "        FOREIGN KEY (category_id) REFERENCES SportRadar.Categories_table(category_id)\n",
    "    )\n",
    "''')\n",
    "\n",
    "# Prepare the insert statement\n",
    "insert_into = '''\n",
    "    INSERT IGNORE INTO SportRadar.Competitions_table \n",
    "    (competition_id, competition_name, parent_id, type, gender, category_id) \n",
    "    VALUES (%s, %s, %s, %s, %s, %s)\n",
    "'''\n",
    "\n",
    "# Insert the rows through the loop\n",
    "for index, row in Competitions_table.iterrows():\n",
    "    try:\n",
    "        # Corrected mapping for the columns\n",
    "        Mycursor.execute(insert_into, (\n",
    "            row['competition_id'], \n",
    "            row['name'],  # This is the correct column name for competition_name\n",
    "            row['parent_id'], \n",
    "            row['type'], \n",
    "            row['gender'], \n",
    "            row['category_id']\n",
    "        ))\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting row {index}: {row.to_dict()}\\nError: {e}\")\n",
    "\n",
    "# Commit the transaction\n",
    "mydb.commit()\n",
    "\n",
    "# Ensure the data has been stored\n",
    "Mycursor.execute('SELECT COUNT(*) FROM SportRadar.Competitions_table')\n",
    "row_count = Mycursor.fetchone()[0]\n",
    "print(f'The data has been uploaded. Total rows in table: {row_count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 617 entries, 0 to 616\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   complex_id    617 non-null    object\n",
      " 1   complex_name  617 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 9.8+ KB\n",
      "the table has been created\n",
      "The data has been uploaded. Total rows in table:Â 617\n"
     ]
    }
   ],
   "source": [
    "# import file to store\n",
    "df=pd.read_csv(r'C:\\Users\\Nithiyaasri G\\python projects\\Mini_Project\\venv\\Scripts\\table_3.csv')\n",
    "Complexes_table=df.copy()\n",
    "\n",
    "# Data Preprocessing\n",
    "\n",
    "# information about dataset\n",
    "Complexes_table.info()\n",
    "# drop duplicates\n",
    "Complexes_table.drop_duplicates(subset=['complex_id'],inplace=True)\n",
    "\n",
    "\n",
    "# create table \n",
    "Mycursor.execute('create table SportRadar.Complexes_table(complex_id varchar(50),complex_name varchar(100) not null,primary key(complex_id))')\n",
    "print('the table has been created')\n",
    "\n",
    "# values to store \n",
    "insert_into='insert ignore into SportRadar.Complexes_table(complex_id,complex_name)values(%s,%s)'\n",
    "#insert the rows through the loop\n",
    "for index,row in Complexes_table.iterrows():\n",
    "    try:\n",
    "        Mycursor.execute(insert_into,(row['complex_id'],row['complex_name']))\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting row {index}: {row.to_dict()}\\nError: {e}\")\n",
    "#commit changes        \n",
    "mydb.commit()\n",
    "\n",
    "# ensure the data has been stored\n",
    "Mycursor.execute('select count(*) from SportRadar.Complexes_table')\n",
    "row_count=Mycursor.fetchone()[0]\n",
    "print(f'The data has been uploaded. Total rows in table:Â {row_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3187 entries, 0 to 3186\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   complex_id    3187 non-null   object\n",
      " 1   venue_id      3187 non-null   object\n",
      " 2   venue_name    3187 non-null   object\n",
      " 3   city_name     3187 non-null   object\n",
      " 4   country_name  3187 non-null   object\n",
      " 5   country_code  3187 non-null   object\n",
      " 6   timezone      3187 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 174.4+ KB\n",
      "complex_id      0\n",
      "venue_id        0\n",
      "venue_name      0\n",
      "city_name       0\n",
      "country_name    0\n",
      "country_code    0\n",
      "timezone        0\n",
      "dtype: int64\n",
      "the table has been created\n",
      "The data has been uploaded. Total rows in table:Â 3187\n"
     ]
    }
   ],
   "source": [
    "# import file to store\n",
    "df=pd.read_csv(r'C:\\Users\\Nithiyaasri G\\python projects\\Mini_Project\\venv\\Scripts\\table_4.csv')\n",
    "Venues_table=df.copy()\n",
    "\n",
    "# Data Preprocessing\n",
    "\n",
    "#informtion about the dataset\n",
    "Venues_table.info()\n",
    "#check null values by related columns\n",
    "missing=Venues_table.loc[Venues_table['timezone'].isna(),['country_name','city_name','timezone']]\n",
    "missing.drop_duplicates()\n",
    "# mapping the missing timezone\n",
    "fill_missing = {('France', 'Orchies'): 'Europe/Paris',('Singapore', 'Kallang'): 'Asia/Singapore',('China', 'Zhuhai'): 'Asia/Shanghai',('Russia', 'Moscow'): 'Europe/Moscow',('Chile', 'Vina del Mar'): 'America/Santiago',('China', 'Liuzhou'): 'Asia/Shanghai',('Uruguay', 'Punta del Este'): 'America/Montevideo',('Austria', 'Tulln'): 'Europe/Vienna',('Monaco', 'Monte Carlo'): 'Europe/Paris',('Germany', 'Baden-Wurttemberg'): 'Europe/Berlin',('Switzerland', 'Montreux'): 'Europe/Zurich',('China', 'Jiujiang'): 'Asia/Shanghai',('France', 'Decines-Charpieu'): 'Europe/Paris',('Thailand','Nonthaburi'):'Asia/Bangkok'}\n",
    "# fill missing values by 'combine key' column\n",
    "Venues_table['combined_key'] = list(zip(Venues_table['country_name'], Venues_table['city_name']))\n",
    "Venues_table['timezone'] = Venues_table['combined_key'].map(fill_missing).fillna(Venues_table['timezone'])\n",
    "#drop the column\n",
    "Venues_table.drop(columns=['combined_key'], inplace=True)\n",
    "# check null values are there  \n",
    "print(Venues_table.isna().sum())\n",
    "\n",
    "\n",
    "\n",
    "# create table \n",
    "Mycursor.execute('create table SportRadar.Venues_table(venue_id varchar(50),venue_name varchar(100) not null,city_name varchar(100) not null,country_name varchar(100) not null,country_code char(3) not null,timezone varchar(100) not null,complex_id varchar(50),primary key(venue_id),foreign key (complex_id) references SportRadar.Complexes_table(complex_id))')\n",
    "print('the table has been created')\n",
    "\n",
    "# values to store \n",
    "insert_into='insert ignore into SportRadar.Venues_table(venue_id,venue_name,city_name,country_name,country_code,timezone,complex_id)values(%s,%s,%s,%s,%s,%s,%s)'\n",
    "\n",
    "#insert the rows through the loop\n",
    "for index,row in Venues_table.iterrows():\n",
    "    try:\n",
    "        Mycursor.execute(insert_into,(row['venue_id'],row['venue_name'],row['city_name'],row['country_name'],row['country_code'],row['timezone'],row['complex_id']))\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting row {index}: {row.to_dict()}\\nError: {e}\")\n",
    "\n",
    "#commit changes\n",
    "mydb.commit()\n",
    "\n",
    "# ensure the data has been stored\n",
    "Mycursor.execute('select count(*) from SportRadar.Venues_table')\n",
    "row_count=Mycursor.fetchone()[0]\n",
    "print(f'The data has been uploaded. Total rows in table:Â {row_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 5 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   rank                 1000 non-null   int64 \n",
      " 1   movement             1000 non-null   int64 \n",
      " 2   points               1000 non-null   int64 \n",
      " 3   competitions_played  1000 non-null   int64 \n",
      " 4   competitor_id        1000 non-null   object\n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 39.2+ KB\n",
      "rank                   0\n",
      "movement               0\n",
      "points                 0\n",
      "competitions_played    0\n",
      "competitor_id          0\n",
      "dtype: int64\n",
      "The table has been created (or already exists).\n",
      "Data has been uploaded successfully.\n",
      "The data has been uploaded. Total rows in table: 502\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "\n",
    "# Assuming you have established a connection to your MySQL database\n",
    "# mydb = pymysql.connect(...)\n",
    "# Mycursor = mydb.cursor()\n",
    "\n",
    "# Import the CSV file\n",
    "df = pd.read_csv(r'C:\\Users\\Nithiyaasri G\\python projects\\Mini_Project\\venv\\Scripts\\table_5.csv')\n",
    "Competitor_Rankings_table = df.copy()\n",
    "\n",
    "# Data Preprocessing\n",
    "\n",
    "# Information about dataset\n",
    "Competitor_Rankings_table.info()\n",
    "\n",
    "# Drop duplicates based on the 'rank' column (update column name if needed)\n",
    "Competitor_Rankings_table.drop_duplicates(subset=['rank'], inplace=True)\n",
    "\n",
    "# Check for null values\n",
    "print(Competitor_Rankings_table.isna().sum())\n",
    "\n",
    "# Create table if it doesn't already exist\n",
    "create_table_query = '''\n",
    "CREATE TABLE IF NOT EXISTS SportRadar.Competitor_Rankings_table (\n",
    "    rank_id INT AUTO_INCREMENT,\n",
    "    `rank` INT NOT NULL,\n",
    "    movement INT NOT NULL,\n",
    "    points INT NOT NULL,\n",
    "    competitions_played INT NOT NULL,\n",
    "    competitor_id VARCHAR(50),\n",
    "    PRIMARY KEY (rank_id),\n",
    "    FOREIGN KEY (competitor_id) REFERENCES SportRadar.competitors_table(competitor_id)\n",
    ");\n",
    "'''\n",
    "Mycursor.execute(create_table_query)\n",
    "print('The table has been created (or already exists).')\n",
    "\n",
    "# Prepare the insert query\n",
    "insert_into = '''INSERT IGNORE INTO SportRadar.Competitor_Rankings_table\n",
    "                 (`rank`, movement, points, competitions_played, competitor_id)\n",
    "                 VALUES (%s, %s, %s, %s, %s)'''\n",
    "\n",
    "# Convert dataframe to list of tuples for batch insertion\n",
    "data_to_insert = Competitor_Rankings_table[['rank', 'movement', 'points', 'competitions_played', 'competitor_id']].values.tolist()\n",
    "\n",
    "# Insert data in bulk using executemany for better performance\n",
    "try:\n",
    "    Mycursor.executemany(insert_into, data_to_insert)\n",
    "    mydb.commit()\n",
    "    print(\"Data has been uploaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during bulk insert: {e}\")\n",
    "\n",
    "# Ensure the data has been stored\n",
    "Mycursor.execute('SELECT COUNT(*) FROM SportRadar.Competitor_Rankings_table')\n",
    "row_count = Mycursor.fetchone()[0]\n",
    "print(f'The data has been uploaded. Total rows in table: {row_count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   competitor_id  1000 non-null   object\n",
      " 1   name           1000 non-null   object\n",
      " 2   country        1000 non-null   object\n",
      " 3   country_code   936 non-null    object\n",
      " 4   abbreviation   1000 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 39.2+ KB\n",
      "competitor_id    0\n",
      "name             0\n",
      "country          0\n",
      "country_code     0\n",
      "abbreviation     0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nithiyaasri G\\AppData\\Local\\Temp\\ipykernel_17156\\1383650677.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  competitors_table['country_code'].fillna('NTL',inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the table has been created\n",
      "The data has been uploaded. Total rows in table:Â 1000\n"
     ]
    }
   ],
   "source": [
    "# import file to store\n",
    "df=pd.read_csv(r'C:\\Users\\Nithiyaasri G\\python projects\\Mini_Project\\venv\\Scripts\\table_6.csv')\n",
    "competitors_table=df.copy()\n",
    "\n",
    "# Data Preprocessing\n",
    "\n",
    "# information about dataet\n",
    "competitors_table.info()\n",
    "# Drop duplicate rows based on 'competitor_id'\n",
    "competitors_table.drop_duplicates(subset=['competitor_id'],inplace=True)\n",
    "# check null values\n",
    "competitors_table.loc[competitors_table['country_code'].isna(),'country']\n",
    "competitors_table[competitors_table['country']=='Neutral']\n",
    "competitors_table['country_code'].fillna('NTL',inplace=True)\n",
    "# ensure the null values\n",
    "print(competitors_table.isna().sum())\n",
    "\n",
    "\n",
    "# create table \n",
    "Mycursor.execute('create table SportRadar.competitors_table(competitor_id varchar(50),name varchar(100) not null,country varchar(100) not null,country_code char(3) not null,abbreviation varchar(10) not null,primary key (competitor_id))')\n",
    "print('the table has been created')\n",
    "# values to store \n",
    "insert_into='insert ignore into SportRadar.competitors_table(competitor_id,name,country,country_code,abbreviation)values(%s,%s,%s,%s,%s)'\n",
    "\n",
    "#insert the rows through the loop\n",
    "for index,row in competitors_table.iterrows():\n",
    "    try:\n",
    "        Mycursor.execute(insert_into,(row['competitor_id'],row['name'],row['country'],row['country_code'],row['abbreviation']))\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting row {index}: {row.to_dict()}\\nError: {e}\")\n",
    "\n",
    "# committ chanes        \n",
    "mydb.commit()\n",
    "\n",
    "# ensure the data has been stored\n",
    "Mycursor.execute('select count(*) from SportRadar.competitors_table')\n",
    "row_count=Mycursor.fetchone()[0]\n",
    "print(f'The data has been uploaded. Total rows in table:Â {row_count}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
